import requests
from bs4 import BeautifulSoup
import pandas as pd
from google.colab import files

# Daftar grid
grids = [
    2096,2097,2098,2116,2117,2118,2119,2120,2121,2122,2123,
    2138,2139,2140,2141,2142,2143,2144,2145,2146,
    2170,2171,2172,2173,2174,2175,2176,2177,2178,
    2211,2212,2213,2214,2215,2216,2217,2218,2219,
    2248,2249,2250,2251
]

# Nama bulan
bulan = ["Jan","Feb","Mar","Apr","Mei","Jun","Jul","Agu","Sep","Okt","Nov","Des","Tahunan"]

data_all = []

for grid in grids:
    url = f"https://hidrologi.net/hujanbulanantrmm/{grid}"
    try:
        resp = requests.get(url, timeout=15)
        resp.raise_for_status()
    except Exception as e:
        print(f"Gagal akses TRMM-{grid}: {e}")
        continue

    soup = BeautifulSoup(resp.text, "html.parser")
    rows = soup.find_all("tr")

    rata_rata_data = None
    for row in rows:
        cells = [c.get_text(strip=True) for c in row.find_all("td")]
        if cells and cells[0].startswith("Rata-rata"):
            rata_rata_data = cells[1:]
            break

    if rata_rata_data and len(rata_rata_data) >= 13:
        hasil = {"Grid": f"TRMM-{grid}"}
        for i in range(len(bulan)):
            hasil[bulan[i]] = rata_rata_data[i]
        data_all.append(hasil)
    else:
        print(f"Tidak menemukan data rata-rata untuk TRMM-{grid}")

# Gabung semua ke dataframe
df = pd.DataFrame(data_all)

# Simpan ke file dengan nama tetap
filename = "curah_hujan_rata2.csv"
df.to_csv(filename, index=False)

# Tampilkan sebagian isi
print(df.head())

# Download otomatis
files.download(filename)
